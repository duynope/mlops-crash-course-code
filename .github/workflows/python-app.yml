name: Data Pipeline Workflow

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  setup_environment:
    runs-on: ubuntu-latest
    container:
      image: ubuntu:20.04
      options: --user=root

    steps:
      - name: Install Python 3.9 and Docker
        run: |
          apt-get update
          apt-get install -y python3.9 python3.9-distutils python3-pip apt-transport-https ca-certificates curl software-properties-common
          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -
          add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable"
          apt-get update
          apt-get install -y docker-ce docker-ce-cli containerd.io
          python3.9 -m pip install --upgrade pip
          ln -sf /usr/bin/python3.9 /usr/bin/python

  build_data_pipeline:
    needs: setup_environment
    runs-on: ubuntu-latest
    container:
      image: ubuntu:20.04

    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Build data pipeline
        working-directory: data_pipeline
        run: |
          echo "Building data pipeline.."
          make build_image

  test_data_pipeline:
    needs: setup_environment
    runs-on: ubuntu-latest
    container:
      image: ubuntu:20.04

    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Test data pipeline
        run: |
          echo "Testing data pipeline.."

  deploy_data_pipeline:
    needs: setup_environment
    runs-on: ubuntu-latest
    container:
      image: ubuntu:20.04

    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Deploy data pipeline
        working-directory: data_pipeline
        run: |
          make deploy_dags
